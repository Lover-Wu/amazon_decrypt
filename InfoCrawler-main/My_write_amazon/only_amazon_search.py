import re
import time
import json
import csv
from typing import List, Dict, Optional
from urllib.parse import urljoin
import os
from DrissionPage import ChromiumPage, ChromiumOptions


class AmazonCrawler:
    """äºšé©¬é€Šå•†å“æœç´¢çˆ¬è™«ï¼ˆç²¾ç®€ç‰ˆï¼‰"""

    def __init__(self, headless: bool = False, use_saved_login: bool = True,
                 browser_type: str = 'edge'):
        """
        åˆå§‹åŒ–çˆ¬è™«

        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼
            use_saved_login: æ˜¯å¦ä½¿ç”¨å·²ä¿å­˜çš„ç™»å½•çŠ¶æ€
            browser_type: æµè§ˆå™¨ç±»å‹ ('edge' æˆ– 'chrome')
        """
        self.page = None
        self.headless = headless
        self.use_saved_login = use_saved_login
        self.browser_type = browser_type.lower()
        self.base_url = "https://www.amazon.com"

        # äºšé©¬é€Šä¸“ç”¨é€‰æ‹©å™¨é…ç½®
        self.search_config = {
            'home_url': self.base_url,
            'search_box_selector': '#twotabsearchtextbox',
            'search_btn_selector': '#nav-search-submit-button',
            'result_selectors': [
                'xpath://div[@data-component-type="s-search-result"]',
                'xpath://div[@role="listitem"][@data-asin]',
                'css:div.s-result-item[data-asin]'
            ]
        }

        self._init_browser()

    def _init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é…ç½®"""
        print(f"ğŸš€ å¯åŠ¨ {'Microsoft Edge' if self.browser_type == 'edge' else 'Google Chrome'} æµè§ˆå™¨...")
        co = ChromiumOptions()

        # è®¾ç½®æµè§ˆå™¨è·¯å¾„
        if self.browser_type == 'edge':
            edge_paths = [
                r'C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe',
                r'C:\Program Files\Microsoft\Edge\Application\msedge.exe',
                os.path.expanduser(r'~\AppData\Local\Microsoft\Edge\Application\msedge.exe'),
            ]

            for path in edge_paths:
                if os.path.exists(path):
                    co.set_browser_path(path)
                    print(f"âœ… ä½¿ç”¨ Microsoft Edge: {path}")
                    break
            else:
                print("âš ï¸ æœªæ‰¾åˆ° Edge æµè§ˆå™¨ï¼Œå°†å°è¯•ç³»ç»Ÿé»˜è®¤æµè§ˆå™¨")
        else:
            chrome_paths = [
                r'C:\Program Files\Google\Chrome\Application\chrome.exe',
                r'C:\Program Files (x86)\Google\Chrome\Application\chrome.exe',
                os.path.expanduser(r'~\AppData\Local\Google\Chrome\Application\chrome.exe'),
            ]

            for path in chrome_paths:
                if os.path.exists(path):
                    co.set_browser_path(path)
                    print(f"âœ… ä½¿ç”¨ Google Chrome: {path}")
                    break
            else:
                print("âš ï¸ æœªæ‰¾åˆ° Chrome æµè§ˆå™¨ï¼Œå°†å°è¯•ç³»ç»Ÿé»˜è®¤æµè§ˆå™¨")

        # æµè§ˆå™¨é€‰é¡¹
        co.set_argument('--disable-blink-features=AutomationControlled')
        co.set_argument('--disable-gpu')
        co.set_argument('--no-sandbox')
        co.set_argument('--disable-dev-shm-usage')

        if self.browser_type == 'edge':
            co.set_argument('--lang=zh-CN')
            co.set_user_agent(
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                '(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
            )
        else:
            co.set_user_agent(
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                '(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )

        # ç”¨æˆ·æ•°æ®ç›®å½•
        if self.use_saved_login:
            user_data_dir = os.path.join(os.path.dirname(__file__), 'amazon_browser_data')
            # ç¡®ä¿ç›®å½•å­˜åœ¨å¹¶å¯å†™
            self._ensure_user_data_dir(user_data_dir)
            co.set_user_data_path(user_data_dir)
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•: {user_data_dir}")

            # ä¿å­˜ç™»å½•æ—¶éœ€è¦å¯è§æ¨¡å¼ä»¥ä¾¿æ‰‹åŠ¨ç™»å½•å¹¶ä¿å­˜ä¼šè¯
            if self.headless:
                print("âš ï¸ use_saved_login å·²å¯ç”¨ï¼Œå¼ºåˆ¶å…³é—­ headless æ¨¡å¼ä»¥ä¿ç•™ç™»å½•ä¿¡æ¯ï¼ˆéœ€è¦æ‰‹åŠ¨ç™»å½•ï¼‰")
                self.headless = False

        # æ˜¯å¦æ— å¤´æ¨¡å¼
        if self.headless:
            co.headless()
        else:
            co.headless(False)
            co.set_argument('--start-maximized')

        # åˆ›å»ºé¡µé¢
        try:
            self.page = ChromiumPage(addr_or_opts=co)

            # éšè—è‡ªåŠ¨åŒ–ç‰¹å¾ï¼ˆå®¹é”™ï¼‰
            try:
                self.page.run_js('''
                    Object.defineProperty(navigator, 'webdriver', {
                        get: () => undefined
                    });
                ''')
            except Exception:
                pass

            print("âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")

            # å¦‚æœå¯ç”¨ä¿å­˜ç™»å½•ï¼Œå¯åŠ¨åæ£€æŸ¥æ˜¯å¦å·²ç™»å½• Amazonï¼Œå¦åˆ™æç¤ºæ‰‹åŠ¨ç™»å½•
            if self.use_saved_login:
                time.sleep(1)
                try:
                    self._ensure_logged_in_or_prompt()
                except Exception as e:
                    print(f"âš ï¸ ç™»å½•æ£€æµ‹è¿‡ç¨‹å‡ºé”™: {e}")

        except Exception as e:
            print(f"âŒ å¯åŠ¨æµè§ˆå™¨å¤±è´¥: {e}")
            raise

    def search_products(self, keyword: str, max_pages: int = 3) -> List[Dict]:
        """
        æœç´¢äºšé©¬é€Šå•†å“

        Args:
            keyword: æœç´¢å…³é”®è¯
            max_pages: æœ€å¤§çˆ¬å–é¡µæ•°

        Returns:
            å•†å“ä¿¡æ¯åˆ—è¡¨
        """
        all_products = []

        try:
            # æ‰“å¼€äºšé©¬é€Šé¦–é¡µ
            print(f"æ­£åœ¨æ‰“å¼€ {self.base_url} ...")
            self.page.get(self.base_url)
            time.sleep(2)

            # æ‰§è¡Œæœç´¢
            self._perform_search(keyword)

            # é€é¡µçˆ¬å–
            for page_num in range(1, max_pages + 1):
                print(f"\n{'=' * 50}")
                print(f"æ­£åœ¨çˆ¬å–ç¬¬ {page_num} é¡µ...")
                print(f"{'=' * 50}")

                # ç­‰å¾…å•†å“åŠ è½½
                self._wait_for_products()

                # æå–å•†å“ä¿¡æ¯
                products = self._extract_products()
                all_products.extend(products)
                print(f"âœ… ç¬¬ {page_num} é¡µæå–åˆ° {len(products)} ä¸ªå•†å“")

                # å¦‚æœä¸æ˜¯æœ€åä¸€é¡µï¼Œå°è¯•ç¿»é¡µ
                if page_num < max_pages:
                    if not self._go_next_page():
                        print("âš ï¸ æ²¡æœ‰ä¸‹ä¸€é¡µäº†ï¼Œåœæ­¢çˆ¬å–")
                        break

            print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_products)} ä¸ªå•†å“æ•°æ®")
            return all_products

        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            return all_products

    def _perform_search(self, keyword: str):
        """æ‰§è¡Œæœç´¢"""
        try:
            print(f"æœç´¢å…³é”®è¯: {keyword}")

            # æŸ¥æ‰¾æœç´¢æ¡†
            search_box = self.page.ele(self.search_config['search_box_selector'], timeout=10)
            if not search_box:
                raise Exception("æ‰¾ä¸åˆ°æœç´¢æ¡†")

            # æ¸…ç©ºå¹¶è¾“å…¥å…³é”®è¯
            search_box.clear()
            search_box.input(keyword)
            time.sleep(1)

            # æŸ¥æ‰¾æœç´¢æŒ‰é’®å¹¶ç‚¹å‡»
            search_btn = self.page.ele(self.search_config['search_btn_selector'], timeout=5)
            if search_btn:
                search_btn.click()
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æŒ‰é’®ï¼ŒæŒ‰å›è½¦é”®
                search_box.input('\n')

            print("âœ… æœç´¢è¯·æ±‚å·²æäº¤")
            time.sleep(3)

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

    def _wait_for_products(self, timeout: int = 10):
        """ç­‰å¾…å•†å“åŠ è½½"""
        print("ç­‰å¾…å•†å“åŠ è½½...")

        start_time = time.time()
        while time.time() - start_time < timeout:
            for selector in self.search_config['result_selectors']:
                try:
                    elements = self.page.eles(selector)
                    if elements and len(elements) > 0:
                        print(f"âœ… æ‰¾åˆ° {len(elements)} ä¸ªå•†å“")
                        return
                except:
                    continue
            time.sleep(1)

        print("âš ï¸ è¶…æ—¶æœªæ‰¾åˆ°å•†å“")

    def _extract_products(self) -> List[Dict]:
        """æå–å•†å“ä¿¡æ¯"""
        products = []

        try:
            # æŸ¥æ‰¾æ‰€æœ‰å•†å“å…ƒç´ 
            for selector in self.search_config['result_selectors']:
                elements = self.page.eles(selector)
                if elements:
                    product_elements = elements
                    break
            else:
                print("âš ï¸ æœªæ‰¾åˆ°å•†å“å…ƒç´ ")
                return products

            print(f"å¼€å§‹æå– {len(product_elements)} ä¸ªå•†å“ä¿¡æ¯...")

            for idx, element in enumerate(product_elements, 1):
                try:
                    product_data = self._extract_single_product(element, idx)
                    if product_data:
                        products.append(product_data)

                        # æ˜¾ç¤ºè¿›åº¦
                        if idx % 10 == 0:
                            print(f"  å·²å¤„ç† {idx}/{len(product_elements)} ä¸ªå•†å“")

                except Exception as e:
                    print(f"âš ï¸ æå–å•†å“ {idx} æ—¶å‡ºé”™: {e}")
                    continue

            return products

        except Exception as e:
            print(f"âŒ æå–å•†å“åˆ—è¡¨å¤±è´¥: {e}")
            return products

    def _extract_single_product(self, element, index: int) -> Optional[Dict]:
        """æå–å•ä¸ªå•†å“ä¿¡æ¯"""
        try:
            product = {'index': index}

            # 1. ASIN (Amazonå•†å“ID)
            asin = element.attr('data-asin')
            if not asin:
                # å°è¯•ä»é“¾æ¥ä¸­æå–ASIN
                link_elem = element.ele('xpath:.//a[contains(@href, "/dp/")]')
                if link_elem:
                    href = link_elem.attr('href') or ''
                    # ä»URLä¸­æå–ASIN
                    match = re.search(r'/dp/([A-Z0-9]{10})', href)
                    if match:
                        asin = match.group(1)

            product['asin'] = asin or ''

            # 2. å•†å“æ ‡é¢˜
            title_elem = element.ele('xpath:.//h2//span')
            if title_elem:
                product['title'] = self._clean_text(title_elem.text or '')
            else:
                product['title'] = ''

            # 3. ä»·æ ¼ä¿¡æ¯
            price_data = self._extract_price(element)
            product.update(price_data)

            # 4. å•†å“é“¾æ¥
            link = self._extract_link(element)
            product['url'] = link

            # 5. å•†å“ç®€ä»‹/æè¿°
            description = self._extract_description(element)
            product['description'] = description

            # 6. è¯„åˆ†å’Œè¯„è®ºæ•°ï¼ˆå¯é€‰ï¼‰
            rating_info = self._extract_rating(element)
            product.update(rating_info)

            # æ¸…ç†ç©ºå€¼
            product = {k: v for k, v in product.items() if v not in [None, '', []]}

            return product

        except Exception as e:
            print(f"æå–å•†å“ä¿¡æ¯å¤±è´¥: {e}")
            return None

    def _extract_price(self, element) -> Dict:
        """æå–ä»·æ ¼ä¿¡æ¯"""
        price_info = {
            'price': '',
            'original_price': '',
            'discount_price': '',
            'currency': 'USD'
        }

        try:
            # æŸ¥æ‰¾æ‰€æœ‰ä»·æ ¼å…ƒç´ 
            price_elements = element.eles('xpath:.//span[@class="a-price"]//span[@class="a-offscreen"]')

            if price_elements:
                # ç¬¬ä¸€ä¸ªä»·æ ¼é€šå¸¸æ˜¯å½“å‰ä»·æ ¼
                if len(price_elements) >= 1:
                    price_text = price_elements[0].text or ''
                    price_info['price'] = self._clean_price(price_text)

                # ç¬¬äºŒä¸ªä»·æ ¼å¯èƒ½æ˜¯åŸä»·ï¼ˆæŠ˜æ‰£æƒ…å†µï¼‰
                if len(price_elements) >= 2:
                    original_text = price_elements[1].text or ''
                    price_info['original_price'] = self._clean_price(original_text)

                    # å¦‚æœæœ‰åŸä»·ï¼Œå½“å‰ä»·æ ¼å°±æ˜¯æŠ˜æ‰£ä»·
                    if price_info['original_price']:
                        price_info['discount_price'] = price_info['price']

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–é€‰æ‹©å™¨
            if not price_info['price']:
                whole_price = element.ele('xpath:.//span[@class="a-price-whole"]')
                if whole_price:
                    price_info['price'] = whole_price.text or ''

            return price_info

        except Exception as e:
            print(f"æå–ä»·æ ¼å¤±è´¥: {e}")
            return price_info

    def _extract_link(self, element) -> str:
        """æå–å•†å“é“¾æ¥"""
        try:
            link_elem = element.ele('xpath:.//a[contains(@href, "/dp/") or contains(@href, "/gp/")]')
            if link_elem:
                href = link_elem.attr('href') or ''
                if href:
                    # ç¡®ä¿æ˜¯å®Œæ•´URL
                    if href.startswith('/'):
                        return urljoin(self.base_url, href)
                    elif href.startswith('http'):
                        return href
                    else:
                        return urljoin(self.base_url, '/' + href.lstrip('/'))
            return ''
        except:
            return ''

    def _extract_description(self, element) -> str:
        """æå–å•†å“ç®€ä»‹"""
        try:
            # å°è¯•å¤šä¸ªæè¿°é€‰æ‹©å™¨
            selectors = [
                'xpath:.//span[contains(@class, "a-color-secondary")]',
                'xpath:.//div[contains(@class, "a-section")]//span',
                'xpath:.//div[contains(@class, "a-row")]//span'
            ]

            for selector in selectors:
                desc_elem = element.ele(selector)
                if desc_elem:
                    text = desc_elem.text or ''
                    if text and len(text.strip()) > 10:
                        return self._clean_text(text)[:200]  # é™åˆ¶é•¿åº¦

            return ''
        except:
            return ''

    def _extract_rating(self, element) -> Dict:
        """æå–è¯„åˆ†ä¿¡æ¯"""
        rating_info = {
            'rating': '',
            'review_count': ''
        }

        try:
            # æå–è¯„åˆ†
            rating_elem = element.ele('xpath:.//span[@class="a-icon-alt"]')
            if rating_elem:
                rating_text = rating_elem.text or ''
                # æå–æ•°å­—è¯„åˆ†ï¼Œå¦‚ "4.5 out of 5 stars"
                match = re.search(r'([\d.]+) out of 5', rating_text)
                if match:
                    rating_info['rating'] = match.group(1)

            # æå–è¯„è®ºæ•°
            review_elem = element.ele('xpath:.//span[contains(@class, "a-size-base")]')
            if review_elem:
                review_text = review_elem.text or ''
                # æå–æ•°å­—
                numbers = re.findall(r'\d+', review_text.replace(',', ''))
                if numbers:
                    rating_info['review_count'] = numbers[0]

            return rating_info
        except:
            return rating_info

    def _clean_price(self, price_text: str) -> str:
        """æ¸…ç†ä»·æ ¼æ–‡æœ¬"""
        if not price_text:
            return ''

        # ç§»é™¤è´§å¸ç¬¦å·å’Œç©ºæ ¼
        cleaned = re.sub(r'[^\d.,]', '', price_text)
        return cleaned.strip()

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not text:
            return ""

        # ç§»é™¤å¤šä½™ç©ºæ ¼å’Œæ¢è¡Œ
        text = re.sub(r'\s+', ' ', text)
        text = text.strip()

        # ç§»é™¤æ§åˆ¶å­—ç¬¦
        text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)

        return text

    def _go_next_page(self) -> bool:
        """ç¿»åˆ°ä¸‹ä¸€é¡µ"""
        try:
            # æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’®
            next_btn = self.page.ele('css:a.s-pagination-next', timeout=5)

            if next_btn and 's-pagination-disabled' not in (next_btn.attr('class') or ''):
                next_btn.click()
                print("âœ… å·²ç¿»é¡µï¼Œç­‰å¾…æ–°é¡µé¢åŠ è½½...")
                time.sleep(3)  # ç­‰å¾…æ–°é¡µé¢åŠ è½½
                return True
            else:
                print("âš ï¸ ä¸‹ä¸€é¡µæŒ‰é’®ä¸å¯ç”¨æˆ–å·²ç¦ç”¨")
                return False

        except Exception as e:
            print(f"âŒ ç¿»é¡µå¤±è´¥: {e}")
            return False

    def save_results(self, products: List[Dict], filename: str = None):
        """
        ä¿å­˜çˆ¬å–ç»“æœ

        Args:
            products: å•†å“åˆ—è¡¨
            filename: ä¿å­˜æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
        """
        if not filename:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"amazon_products_{timestamp}.json"

        # å‡†å¤‡ä¿å­˜çš„æ•°æ®
        data_to_save = {
            'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_products': len(products),
            'products': products
        }

        # ä¿å­˜ä¸ºJSON
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {filename}")

            # åŒæ—¶ä¿å­˜ä¸ºCSVä¾¿äºæŸ¥çœ‹
            csv_filename = filename.replace('.json', '.csv')
            self._save_to_csv(products, csv_filename)

        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")

    def _save_to_csv(self, products: List[Dict], filename: str):
        """ä¿å­˜ä¸ºCSVæ–‡ä»¶"""
        try:
            # å®šä¹‰CSVåˆ—
            fieldnames = [
                'index', 'asin', 'title', 'price', 'original_price',
                'discount_price', 'rating', 'review_count', 'url'
            ]

            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()

                for product in products:
                    # åªå†™å…¥éœ€è¦çš„åˆ—
                    row = {
                        'index': product.get('index', ''),
                        'asin': product.get('asin', ''),
                        'title': product.get('title', '')[:100],  # é™åˆ¶æ ‡é¢˜é•¿åº¦
                        'price': product.get('price', ''),
                        'original_price': product.get('original_price', ''),
                        'discount_price': product.get('discount_price', ''),
                        'rating': product.get('rating', ''),
                        'review_count': product.get('review_count', ''),
                        'url': product.get('url', '')
                    }
                    writer.writerow(row)

            print(f"âœ… CSVæ–‡ä»¶å·²ä¿å­˜: {filename}")

        except Exception as e:
            print(f"âŒ ä¿å­˜CSVæ—¶å‡ºé”™: {e}")

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.page:
            try:
                self.page.quit()
                print("âœ… æµè§ˆå™¨å·²å…³é—­")
            except:
                pass

    def _ensure_user_data_dir(self, path: str):
        """ç¡®ä¿ç”¨æˆ·æ•°æ®ç›®å½•å­˜åœ¨å¹¶å¯å†™"""
        try:
            if not os.path.exists(path):
                os.makedirs(path, exist_ok=True)
            # åœ¨ç›®å½•ä¸­åˆ›å»ºä¸€ä¸ªå ä½æ–‡ä»¶ï¼Œç¡®ä¿ç›®å½•æ˜¯å¯å†™çš„
            test_file = os.path.join(path, '.profile_write_test')
            with open(test_file, 'w', encoding='utf-8') as f:
                f.write('ok')
            try:
                os.remove(test_file)
            except Exception:
                pass
        except Exception as e:
            print(f"âš ï¸ æ— æ³•åˆ›å»ºç”¨æˆ·æ•°æ®ç›®å½• {path}: {e}")

    def _ensure_logged_in_or_prompt(self, timeout: int = 180):
        """
        æ£€æŸ¥å½“å‰ profile æ˜¯å¦å·²ç™»å½• Amazonã€‚\
        è‹¥æœªç™»å½•åˆ™ä¿æŒæµè§ˆå™¨å¯è§ï¼Œæç¤ºç”¨æˆ·æ‰‹åŠ¨ç™»å½•ï¼Œç­‰å¾…ç”¨æˆ·å®Œæˆæˆ–è‡ªåŠ¨æ£€æµ‹åˆ°å·²ç™»å½•åç»§ç»­ã€‚
        """
        try:
            print("ğŸ” æ£€æŸ¥æ˜¯å¦å·²ç™»å½• Amazon...")
            # æ‰“å¼€é¦–é¡µä»¥è¯»å–è´¦å·ä¿¡æ¯
            self.page.get(self.base_url)
            time.sleep(2)

            start = time.time()
            prompted = False
            while time.time() - start < timeout:
                acct_elem = None
                try:
                    acct_elem = self.page.ele('#nav-link-accountList-nav-line-1') or self.page.ele('#nav-link-accountList')
                except Exception:
                    acct_elem = None

                text = ''
                try:
                    if acct_elem and acct_elem.text:
                        text = acct_elem.text.strip().lower()
                except Exception:
                    text = ''

                # ç®€å•åˆ¤æ–­ï¼šå¦‚æœæ–‡æœ¬ä¸­æ²¡æœ‰ 'sign'ï¼Œåˆ™è§†ä¸ºå·²ç™»å½•
                if acct_elem and text and 'sign' not in text:
                    print(f"âœ… å·²æ£€æµ‹åˆ°ç™»å½•ï¼š{acct_elem.text.strip()}")
                    return

                if not prompted:
                    print("âš ï¸ æœªæ£€æµ‹åˆ°å·²ç™»å½•è´¦æˆ·ã€‚è¯·åœ¨æ‰“å¼€çš„æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½• Amazonã€‚")
                    print("ç™»å½•å®Œæˆåï¼Œç¨‹åºä¼šè‡ªåŠ¨æ£€æµ‹æˆ–æŒ‰ Enter è·³è¿‡ç­‰å¾…ã€‚")
                    prompted = True

                # æ¯éš”å‡ ç§’æ£€æŸ¥ä¸€æ¬¡
                for _ in range(6):
                    time.sleep(2)
                    try:
                        acct_elem = self.page.ele('#nav-link-accountList-nav-line-1') or self.page.ele('#nav-link-accountList')
                        if acct_elem and acct_elem.text and 'sign' not in acct_elem.text.strip().lower():
                            print(f"âœ… å·²æ£€æµ‹åˆ°ç™»å½•ï¼š{acct_elem.text.strip()}")
                            return
                    except Exception:
                        pass

                try:
                    input("å¦‚æœå·²å®Œæˆç™»å½•ï¼Œè¯·æŒ‰ Enter ç»§ç»­ï¼ˆæˆ–ç­‰å¾…è‡ªåŠ¨æ£€æµ‹ï¼‰...")
                except Exception:
                    # åœ¨æŸäº›åœºæ™¯ input å¯èƒ½ä¸å¯ç”¨ï¼Œç»§ç»­æ£€æµ‹ç›´åˆ°è¶…æ—¶
                    pass

            print("âš ï¸ ç™»å½•æ£€æµ‹è¶…æ—¶ï¼Œç»§ç»­è¿è¡Œï¼ˆåç»­å¯èƒ½ä¼šé‡åˆ°éªŒè¯æˆ–éœ€è¦ç™»å½•ï¼‰ã€‚")
        except Exception as e:
            print(f"âš ï¸ ç™»å½•æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("äºšé©¬é€Šå•†å“æœç´¢çˆ¬è™«")
    print("=" * 60)

    try:
        # ç”¨æˆ·é€‰æ‹©æµè§ˆå™¨
        print("\nè¯·é€‰æ‹©æµè§ˆå™¨:")
        print("1. Microsoft Edge (é»˜è®¤)")
        print("2. Google Chrome")

        browser_choice = input("è¯·è¾“å…¥æ•°å­— (1æˆ–2): ").strip()
        browser_type = 'chrome' if browser_choice == '2' else 'edge'

        # åˆ›å»ºçˆ¬è™«å®ä¾‹
        crawler = AmazonCrawler(
            headless=False,  # æ˜¾ç¤ºæµè§ˆå™¨çª—å£
            use_saved_login=True,  # ä½¿ç”¨ä¿å­˜çš„ç™»å½•çŠ¶æ€
            browser_type=browser_type
        )

        # è¾“å…¥æœç´¢å…³é”®è¯
        print("\nè¯·è¾“å…¥è¦æœç´¢çš„å•†å“å…³é”®è¯:")
        keyword = input("å…³é”®è¯: ").strip()

        if not keyword:
            keyword = "laptop"  # é»˜è®¤å…³é”®è¯
            print(f"ä½¿ç”¨é»˜è®¤å…³é”®è¯: {keyword}")

        # è¾“å…¥çˆ¬å–é¡µæ•°
        print("\nè¯·è¾“å…¥è¦çˆ¬å–çš„é¡µæ•° (å»ºè®®1-3é¡µ):")
        try:
            max_pages = int(input("é¡µæ•°: ").strip() or "1")
        except:
            max_pages = 1
            print(f"ä½¿ç”¨é»˜è®¤é¡µæ•°: {max_pages}")

        # å¼€å§‹çˆ¬å–
        print(f"\nå¼€å§‹çˆ¬å–äºšé©¬é€Š '{keyword}' ...")
        print("è¯·ç­‰å¾…æµè§ˆå™¨åŠ è½½...")

        products = crawler.search_products(keyword, max_pages=max_pages)

        # ä¿å­˜ç»“æœ
        if products:
            crawler.save_results(products)

            # æ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯
            print(f"\nğŸ“Š çˆ¬å–æ‘˜è¦:")
            print(f"   å…³é”®è¯: {keyword}")
            print(f"   å•†å“æ•°é‡: {len(products)}")
            print(f"   æ–‡ä»¶æ ¼å¼: JSONå’ŒCSV")

            # æ˜¾ç¤ºå‰å‡ ä¸ªå•†å“
            print(f"\nğŸ“¦ å‰5ä¸ªå•†å“:")
            for i, product in enumerate(products[:5], 1):
                title = product.get('title', 'æ— æ ‡é¢˜')[:50]
                price = product.get('price', 'æ— ä»·æ ¼')
                rating = product.get('rating', 'æ— è¯„åˆ†')
                print(f"   {i}. {title}")
                print(f"      ä»·æ ¼: ${price} | è¯„åˆ†: {rating}/5")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å•†å“")

    except KeyboardInterrupt:
        print("\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # ç¡®ä¿å…³é—­æµè§ˆå™¨
        try:
            if 'crawler' in locals() and locals().get('crawler'):
                locals().get('crawler').close()
        except:
            pass

    print("\n" + "=" * 60)
    print("ç¨‹åºæ‰§è¡Œå®Œæ¯•")
    print("=" * 60)
    input("æŒ‰ Enter é”®é€€å‡º...")


if __name__ == '__main__':
    main()