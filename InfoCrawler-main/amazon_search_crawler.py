import re
import time
import json
import csv
from typing import List, Dict, Optional, Tuple
from urllib.parse import urljoin
import os
from DrissionPage import ChromiumPage, ChromiumOptions


class EnhancedAmazonSearchCrawler:
    """Amazon æœç´¢ç»“æœçˆ¬è™«ç±»ï¼ˆå¢å¼ºç‰ˆï¼‰"""

    def __init__(self, headless: bool = False, use_saved_login: bool = True,
                 local_port: int = None, browser_type: str = 'edge'):
        """
        åˆå§‹åŒ–çˆ¬è™«
        """
        self.page = None
        self.headless = headless
        self.use_saved_login = use_saved_login
        self.local_port = local_port
        self.browser_type = browser_type.lower()
        self.base_url = "https://www.amazon.com"
        # search_config holds per-site selectors and home URL; can be changed at runtime
        self.search_config = {
            'home_url': self.base_url,
            'search_box_selector': '#twotabsearchtextbox',
            'search_btn_selector': '#nav-search-submit-button',
            'result_selectors': [
                'xpath://div[@role="listitem"][@data-asin]',
                'xpath://div[@data-component-type="s-search-result"]',
                'css:div.s-result-item[data-asin]'
            ]
        }
        self._init_browser()

    def _init_browser(self):
        """åˆå§‹åŒ–æµè§ˆå™¨é…ç½®"""
        if self.local_port:
            print(f"æ­£åœ¨æ¥ç®¡æµè§ˆå™¨ï¼ˆç«¯å£: {self.local_port}ï¼‰...")
            try:
                co = ChromiumOptions()
                co.set_local_port(self.local_port)

                if self.browser_type == 'edge':
                    edge_paths = [
                        r'C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe',
                        r'C:\Program Files\Microsoft\Edge\Application\msedge.exe',
                    ]
                    for path in edge_paths:
                        if os.path.exists(path):
                            co.set_browser_path(path)
                            print(f"âœ… æŒ‡å®š Edge è·¯å¾„: {path}")
                            break

                if not self.headless:
                    co.headless(False)

                self.page = ChromiumPage(co)
                print("âœ… å·²æ¥ç®¡æµè§ˆå™¨")
                return

            except Exception as e:
                print(f"âŒ æ¥ç®¡å¤±è´¥: {e}")
                print("ğŸ”„ å°†è‡ªåŠ¨å¯åŠ¨æ–°æµè§ˆå™¨...")

        print(f"ğŸš€ è‡ªåŠ¨å¯åŠ¨ {'Microsoft Edge' if self.browser_type == 'edge' else 'Chrome'} æµè§ˆå™¨...")
        co = ChromiumOptions()

        if self.browser_type == 'edge':
            edge_paths = [
                r'C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe',
                r'C:\Program Files\Microsoft\Edge\Application\msedge.exe',
            ]
            edge_found = False
            for path in edge_paths:
                if os.path.exists(path):
                    co.set_browser_path(path)
                    print(f"âœ… ä½¿ç”¨ Microsoft Edge: {path}")
                    edge_found = True
                    break
            if not edge_found:
                print("âš ï¸ æœªæ‰¾åˆ° Edgeï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤æµè§ˆå™¨")
        else:
            chrome_paths = [
                r'C:\Program Files\Google\Chrome\Application\chrome.exe',
                r'C:\Program Files (x86)\Google\Chrome\Application\chrome.exe',
            ]
            chrome_found = False
            for path in chrome_paths:
                if os.path.exists(path):
                    co.set_browser_path(path)
                    print(f"âœ… ä½¿ç”¨ Google Chrome: {path}")
                    chrome_found = True
                    break
            if not chrome_found:
                print("âš ï¸ æœªæ‰¾åˆ° Chromeï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤æµè§ˆå™¨")

        co.set_argument('--disable-blink-features=AutomationControlled')
        co.set_argument('--disable-gpu')
        co.set_argument('--no-sandbox')
        co.set_argument('--disable-dev-shm-usage')

        if self.browser_type == 'edge':
            co.set_argument('--disable-features=EdgeTranslate')
            co.set_argument('--disable-component-update')
            co.set_argument('--lang=zh-CN')
            co.set_user_agent(
                'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                '(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edg/120.0.0.0'
            )

        if self.use_saved_login:
            if self.browser_type == 'edge':
                user_data_dir = os.path.join(os.path.dirname(__file__), 'edge_browser_data')
            else:
                user_data_dir = os.path.join(os.path.dirname(__file__), 'browser_data')
            co.set_user_data_path(user_data_dir)
            print(f"âœ… ä½¿ç”¨ç”¨æˆ·æ•°æ®ç›®å½•: {user_data_dir}")

        if self.headless:
            co.headless()
        else:
            co.headless(False)
            co.set_argument('--start-maximized')

        self.page = ChromiumPage(addr_or_opts=co)
        self.page.run_js('''
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        ''')
        print(f"âœ… æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")

    def check_captcha(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦å‡ºç°éªŒè¯ç 
        """
        captcha_indicators = [
            'captcha',
            'robot check',
            'enter the characters',
            'type the characters',
            'solve this puzzle'
        ]

        page_text = self.page.html.lower()
        for indicator in captcha_indicators:
            if indicator in page_text:
                print("âš ï¸ æ£€æµ‹åˆ°éªŒè¯ç ï¼ç¨‹åºæš‚åœï¼Œè¯·äººå·¥å¤„ç†...")
                print("å¤„ç†å®ŒæˆåæŒ‰ Enter ç»§ç»­...")
                input()
                return True
        return False

    def search_products(self, keyword: str, max_pages: int = 5, detailed_extraction: bool = True) -> List[Dict]:
        """
        æœç´¢å•†å“å¹¶çˆ¬å–ç»“æœï¼ˆä¼˜åŒ–ï¼šå‡å°‘ä¸å¿…è¦çš„ sleepï¼Œä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼‰
        æ­¤å‡½æ•°å·²è¢«åŒ…è£…ä¸ºè°ƒç”¨ _search_products_implï¼›ä¿ç•™ä¸ºç©ºä»¥å…¼å®¹æ—§è°ƒç”¨ã€‚
        """
        return self._search_products_impl(keyword, max_pages=max_pages, detailed_extraction=detailed_extraction)

    def _search_products_impl(self, keyword: str, max_pages: int = 5, detailed_extraction: bool = True) -> List[Dict]:
        """
        ç»Ÿä¸€çš„æœç´¢å®ç°ï¼ˆåŸ search_products çš„ä¼˜åŒ–ç‰ˆæœ¬ï¼‰ï¼Œç°åœ¨è¢« wrapper è°ƒç”¨ã€‚
        """
        all_products = []
        try:
            print(f"æ­£åœ¨æ‰“å¼€ {self.search_config.get('home_url', self.base_url)} ...")
            self.page.get(self.search_config.get('home_url', self.base_url))
            # çŸ­ç­‰å¾…é¡µé¢åŠ è½½å¿…è¦èŠ‚ç‚¹
            try:
                # å°è¯•ä½¿ç”¨é…ç½®çš„æŒ‰é’®é€‰æ‹©å™¨çŸ­ç­‰å¾…
                self.page.ele(self.search_config.get('search_btn_selector', ''), timeout=4)
            except:
                pass

            # ä¸€æ¬¡æ€§æ£€æŸ¥éªŒè¯ç 
            if self.check_captcha():
                time.sleep(1)

            self._perform_search(keyword)

            for page_num in range(1, max_pages + 1):
                print(f"\n{'=' * 60}")
                print(f"æ­£åœ¨çˆ¬å–ç¬¬ {page_num} é¡µ...")
                print(f"{'=' * 60}")

                # æå–å•†å“
                products = self._extract_products_enhanced(detailed_mode=detailed_extraction)
                all_products.extend(products)
                print(f"ç¬¬ {page_num} é¡µæå–åˆ° {len(products)} ä¸ªå•†å“")

                if page_num < max_pages:
                    if not self._go_next_page():
                        print("æ²¡æœ‰ä¸‹ä¸€é¡µäº†ï¼Œåœæ­¢çˆ¬å–")
                        break
                    # é¡µé¢è·³è½¬åè¿›è¡Œå°ç­‰å¾…å¹¶æ£€æµ‹æ˜¯å¦å‡ºç°äº§å“åˆ—è¡¨
                    for _ in range(8):  # æœ€å¤šçº¦4s
                        # ä½¿ç”¨é…ç½®çš„ result_selectors
                        found = False
                        for sel in self.search_config.get('result_selectors', []):
                            try:
                                if sel.startswith('xpath:'):
                                    if self.page.eles(sel):
                                        found = True
                                        break
                                else:
                                    if self.page.eles(sel):
                                        found = True
                                        break
                            except:
                                continue
                        if found:
                            break
                        time.sleep(0.5)

            print(f"\nâœ… çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_products)} ä¸ªå•†å“æ•°æ®")
            return all_products

        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            return all_products

    def _perform_search(self, keyword: str):
        """
        æ‰§è¡Œæœç´¢æ“ä½œï¼ˆä½¿ç”¨ self.search_config ä¸­çš„é€‰æ‹©å™¨ï¼Œä½¿å¾—å¯æ”¯æŒä¸åŒç½‘ç«™ï¼‰
        """
        try:
            search_box_selector = self.search_config.get('search_box_selector')
            search_btn_selector = self.search_config.get('search_btn_selector')

            print(f"æœç´¢å…³é”®è¯: {keyword}")

            search_box = None
            if search_box_selector:
                try:
                    search_box = self.page.ele(search_box_selector, timeout=5)
                except Exception:
                    search_box = None

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœç´¢æ¡†ï¼Œå°è¯•åœ¨é¡µé¢ç›´æ¥é€šè¿‡ JS è®¾ç½®æœç´¢å‚æ•°æˆ– raise
            if search_box:
                try:
                    search_box.clear()
                    search_box.input(keyword)
                except Exception:
                    try:
                        # ä½œä¸ºå›é€€ï¼Œç›´æ¥è¾“å…¥å›è½¦
                        search_box.input('\n')
                    except:
                        pass

            # å°è¯•ç‚¹å‡»æˆ–å›è½¦æäº¤ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®çš„æŒ‰é’®é€‰æ‹©å™¨ï¼‰
            if search_btn_selector:
                try:
                    search_btn = self.page.ele(search_btn_selector, timeout=2)
                except Exception:
                    search_btn = None
            else:
                search_btn = None

            if search_btn:
                try:
                    search_btn.click()
                except Exception:
                    # å›é€€åˆ°è¾“å…¥å›è½¦
                    try:
                        if search_box:
                            search_box.input('\n')
                    except:
                        pass
            else:
                # å¦‚æœæ²¡æœ‰æŒ‰é’®ï¼Œåˆ™å°è¯•æŒ‰å›è½¦æäº¤ï¼ˆè‹¥æ‰¾åˆ°äº†è¾“å…¥æ¡†ï¼‰
                if search_box:
                    try:
                        search_box.input('\n')
                    except:
                        pass

            # ç­‰å¾…æœç´¢ç»“æœä¸»è¦å®¹å™¨å‡ºç°ï¼ˆçŸ­è¶…æ—¶ï¼‰
            selectors = self.search_config.get('result_selectors', [])
            found = False
            for _ in range(10):  # æœ€å¤šç­‰å¾…çº¦ 5s
                for sel in selectors:
                    try:
                        eles = self.page.eles(sel)
                    except Exception:
                        eles = []
                    if eles:
                        found = True
                        break
                if found:
                    break
                time.sleep(0.5)

            if not found:
                print("âš ï¸ æœç´¢æäº¤åæœªåœ¨çŸ­æ—¶é—´å†…æ£€æµ‹åˆ°ç»“æœï¼Œå¯èƒ½åŠ è½½è¾ƒæ…¢æˆ–é€‰æ‹©å™¨ä¸åŒ¹é…")

            print("æœç´¢è¯·æ±‚å·²æäº¤")

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

    def _search_products_impl(self, keyword: str, max_pages: int = 5, detailed_extraction: bool = True) -> List[Dict]:
        """
        ç»Ÿä¸€çš„æœç´¢å®ç°ï¼ˆåŸ search_products çš„ä¼˜åŒ–ç‰ˆæœ¬ï¼‰ï¼Œç°åœ¨è¢« wrapper è°ƒç”¨ã€‚
        """
        all_products = []
        try:
            print(f"æ­£åœ¨æ‰“å¼€ {self.search_config.get('home_url', self.base_url)} ...")
            self.page.get(self.search_config.get('home_url', self.base_url))
            # çŸ­ç­‰å¾…é¡µé¢åŠ è½½å¿…è¦èŠ‚ç‚¹
            try:
                # å°è¯•ä½¿ç”¨é…ç½®çš„æŒ‰é’®é€‰æ‹©å™¨çŸ­ç­‰å¾…
                self.page.ele(self.search_config.get('search_btn_selector', ''), timeout=4)
            except:
                pass

            # ä¸€æ¬¡æ€§æ£€æŸ¥éªŒè¯ç 
            if self.check_captcha():
                time.sleep(1)

            self._perform_search(keyword)

            for page_num in range(1, max_pages + 1):
                print(f"\n{'=' * 60}")
                print(f"æ­£åœ¨çˆ¬å–ç¬¬ {page_num} é¡µ...")
                print(f"{'=' * 60}")

                # æå–å•†å“
                products = self._extract_products_enhanced(detailed_mode=detailed_extraction)
                all_products.extend(products)
                print(f"ç¬¬ {page_num} é¡µæå–åˆ° {len(products)} ä¸ªå•†å“")

                if page_num < max_pages:
                    if not self._go_next_page():
                        print("æ²¡æœ‰ä¸‹ä¸€é¡µäº†ï¼Œåœæ­¢çˆ¬å–")
                        break
                    # é¡µé¢è·³è½¬åè¿›è¡Œå°ç­‰å¾…å¹¶æ£€æµ‹æ˜¯å¦å‡ºç°äº§å“åˆ—è¡¨
                    for _ in range(8):  # æœ€å¤šçº¦4s
                        # ä½¿ç”¨é…ç½®çš„ result_selectors
                        found = False
                        for sel in self.search_config.get('result_selectors', []):
                            try:
                                if sel.startswith('xpath:'):
                                    if self.page.eles(sel):
                                        found = True
                                        break
                                else:
                                    if self.page.eles(sel):
                                        found = True
                                        break
                            except:
                                continue
                        if found:
                            break
                        time.sleep(0.5)

            print(f"\nâœ… çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_products)} ä¸ªå•†å“æ•°æ®")
            return all_products

        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            return all_products

    def _perform_search(self, keyword: str):
        """
        æ‰§è¡Œæœç´¢æ“ä½œï¼ˆä½¿ç”¨ self.search_config ä¸­çš„é€‰æ‹©å™¨ï¼Œä½¿å¾—å¯æ”¯æŒä¸åŒç½‘ç«™ï¼‰
        """
        try:
            search_box_selector = self.search_config.get('search_box_selector')
            search_btn_selector = self.search_config.get('search_btn_selector')

            print(f"æœç´¢å…³é”®è¯: {keyword}")

            search_box = None
            if search_box_selector:
                try:
                    search_box = self.page.ele(search_box_selector, timeout=5)
                except Exception:
                    search_box = None

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœç´¢æ¡†ï¼Œå°è¯•åœ¨é¡µé¢ç›´æ¥é€šè¿‡ JS è®¾ç½®æœç´¢å‚æ•°æˆ– raise
            if search_box:
                try:
                    search_box.clear()
                    search_box.input(keyword)
                except Exception:
                    try:
                        # ä½œä¸ºå›é€€ï¼Œç›´æ¥è¾“å…¥å›è½¦
                        search_box.input('\n')
                    except:
                        pass

            # å°è¯•ç‚¹å‡»æˆ–å›è½¦æäº¤ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®çš„æŒ‰é’®é€‰æ‹©å™¨ï¼‰
            if search_btn_selector:
                try:
                    search_btn = self.page.ele(search_btn_selector, timeout=2)
                except Exception:
                    search_btn = None
            else:
                search_btn = None

            if search_btn:
                try:
                    search_btn.click()
                except Exception:
                    # å›é€€åˆ°è¾“å…¥å›è½¦
                    try:
                        if search_box:
                            search_box.input('\n')
                    except:
                        pass
            else:
                # å¦‚æœæ²¡æœ‰æŒ‰é’®ï¼Œåˆ™å°è¯•æŒ‰å›è½¦æäº¤ï¼ˆè‹¥æ‰¾åˆ°äº†è¾“å…¥æ¡†ï¼‰
                if search_box:
                    try:
                        search_box.input('\n')
                    except:
                        pass

            # ç­‰å¾…æœç´¢ç»“æœä¸»è¦å®¹å™¨å‡ºç°ï¼ˆçŸ­è¶…æ—¶ï¼‰
            selectors = self.search_config.get('result_selectors', [])
            found = False
            for _ in range(10):  # æœ€å¤šç­‰å¾…çº¦ 5s
                for sel in selectors:
                    try:
                        eles = self.page.eles(sel)
                    except Exception:
                        eles = []
                    if eles:
                        found = True
                        break
                if found:
                    break
                time.sleep(0.5)

            if not found:
                print("âš ï¸ æœç´¢æäº¤åæœªåœ¨çŸ­æ—¶é—´å†…æ£€æµ‹åˆ°ç»“æœï¼Œå¯èƒ½åŠ è½½è¾ƒæ…¢æˆ–é€‰æ‹©å™¨ä¸åŒ¹é…")

            print("æœç´¢è¯·æ±‚å·²æäº¤")

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

    def search_products(self, keyword: str, max_pages: int = 5, detailed_extraction: bool = True) -> List[Dict]:
        """
        æœç´¢å•†å“å¹¶çˆ¬å–ç»“æœï¼ˆä¼˜åŒ–ï¼šå‡å°‘ä¸å¿…è¦çš„ sleepï¼Œä½¿ç”¨æ˜¾å¼ç­‰å¾…ï¼‰
        æ­¤å‡½æ•°å·²è¢«åŒ…è£…ä¸ºè°ƒç”¨ _search_products_implï¼›ä¿ç•™ä¸ºç©ºä»¥å…¼å®¹æ—§è°ƒç”¨ã€‚
        """
        return self._search_products_impl(keyword, max_pages=max_pages, detailed_extraction=detailed_extraction)

    def _search_products_impl(self, keyword: str, max_pages: int = 5, detailed_extraction: bool = True) -> List[Dict]:
        """
        ç»Ÿä¸€çš„æœç´¢å®ç°ï¼ˆåŸ search_products çš„ä¼˜åŒ–ç‰ˆæœ¬ï¼‰ï¼Œç°åœ¨è¢« wrapper è°ƒç”¨ã€‚
        """
        all_products = []
        try:
            print(f"æ­£åœ¨æ‰“å¼€ {self.search_config.get('home_url', self.base_url)} ...")
            self.page.get(self.search_config.get('home_url', self.base_url))
            # çŸ­ç­‰å¾…é¡µé¢åŠ è½½å¿…è¦èŠ‚ç‚¹
            try:
                # å°è¯•ä½¿ç”¨é…ç½®çš„æŒ‰é’®é€‰æ‹©å™¨çŸ­ç­‰å¾…
                self.page.ele(self.search_config.get('search_btn_selector', ''), timeout=4)
            except:
                pass

            # ä¸€æ¬¡æ€§æ£€æŸ¥éªŒè¯ç 
            if self.check_captcha():
                time.sleep(1)

            self._perform_search(keyword)

            for page_num in range(1, max_pages + 1):
                print(f"\n{'=' * 60}")
                print(f"æ­£åœ¨çˆ¬å–ç¬¬ {page_num} é¡µ...")
                print(f"{'=' * 60}")

                # æå–å•†å“
                products = self._extract_products_enhanced(detailed_mode=detailed_extraction)
                all_products.extend(products)
                print(f"ç¬¬ {page_num} é¡µæå–åˆ° {len(products)} ä¸ªå•†å“")

                if page_num < max_pages:
                    if not self._go_next_page():
                        print("æ²¡æœ‰ä¸‹ä¸€é¡µäº†ï¼Œåœæ­¢çˆ¬å–")
                        break
                    # é¡µé¢è·³è½¬åè¿›è¡Œå°ç­‰å¾…å¹¶æ£€æµ‹æ˜¯å¦å‡ºç°äº§å“åˆ—è¡¨
                    for _ in range(8):  # æœ€å¤šçº¦4s
                        # ä½¿ç”¨é…ç½®çš„ result_selectors
                        found = False
                        for sel in self.search_config.get('result_selectors', []):
                            try:
                                if sel.startswith('xpath:'):
                                    if self.page.eles(sel):
                                        found = True
                                        break
                                else:
                                    if self.page.eles(sel):
                                        found = True
                                        break
                            except:
                                continue
                        if found:
                            break
                        time.sleep(0.5)

            print(f"\nâœ… çˆ¬å–å®Œæˆï¼å…±è·å– {len(all_products)} ä¸ªå•†å“æ•°æ®")
            return all_products

        except Exception as e:
            print(f"âŒ çˆ¬å–è¿‡ç¨‹å‡ºé”™: {e}")
            return all_products

    def _perform_search(self, keyword: str):
        """
        æ‰§è¡Œæœç´¢æ“ä½œï¼ˆä½¿ç”¨ self.search_config ä¸­çš„é€‰æ‹©å™¨ï¼Œä½¿å¾—å¯æ”¯æŒä¸åŒç½‘ç«™ï¼‰
        """
        try:
            search_box_selector = self.search_config.get('search_box_selector')
            search_btn_selector = self.search_config.get('search_btn_selector')

            print(f"æœç´¢å…³é”®è¯: {keyword}")

            search_box = None
            if search_box_selector:
                try:
                    search_box = self.page.ele(search_box_selector, timeout=5)
                except Exception:
                    search_box = None

            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœç´¢æ¡†ï¼Œå°è¯•åœ¨é¡µé¢ç›´æ¥é€šè¿‡ JS è®¾ç½®æœç´¢å‚æ•°æˆ– raise
            if search_box:
                try:
                    search_box.clear()
                    search_box.input(keyword)
                except Exception:
                    try:
                        # ä½œä¸ºå›é€€ï¼Œç›´æ¥è¾“å…¥å›è½¦
                        search_box.input('\n')
                    except:
                        pass

            # å°è¯•ç‚¹å‡»æˆ–å›è½¦æäº¤ï¼ˆä¼˜å…ˆä½¿ç”¨é…ç½®çš„æŒ‰é’®é€‰æ‹©å™¨ï¼‰
            if search_btn_selector:
                try:
                    search_btn = self.page.ele(search_btn_selector, timeout=2)
                except Exception:
                    search_btn = None
            else:
                search_btn = None

            if search_btn:
                try:
                    search_btn.click()
                except Exception:
                    # å›é€€åˆ°è¾“å…¥å›è½¦
                    try:
                        if search_box:
                            search_box.input('\n')
                    except:
                        pass
            else:
                # å¦‚æœæ²¡æœ‰æŒ‰é’®ï¼Œåˆ™å°è¯•æŒ‰å›è½¦æäº¤ï¼ˆè‹¥æ‰¾åˆ°äº†è¾“å…¥æ¡†ï¼‰
                if search_box:
                    try:
                        search_box.input('\n')
                    except:
                        pass

            # ç­‰å¾…æœç´¢ç»“æœä¸»è¦å®¹å™¨å‡ºç°ï¼ˆçŸ­è¶…æ—¶ï¼‰
            selectors = self.search_config.get('result_selectors', [])
            found = False
            for _ in range(10):  # æœ€å¤šç­‰å¾…çº¦ 5s
                for sel in selectors:
                    try:
                        eles = self.page.eles(sel)
                    except Exception:
                        eles = []
                    if eles:
                        found = True
                        break
                if found:
                    break
                time.sleep(0.5)

            if not found:
                print("âš ï¸ æœç´¢æäº¤åæœªåœ¨çŸ­æ—¶é—´å†…æ£€æµ‹åˆ°ç»“æœï¼Œå¯èƒ½åŠ è½½è¾ƒæ…¢æˆ–é€‰æ‹©å™¨ä¸åŒ¹é…")

            print("æœç´¢è¯·æ±‚å·²æäº¤")

        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            raise

    def _extract_products_enhanced(self, detailed_mode: bool = True) -> List[Dict]:
        """
        å¢å¼ºç‰ˆå•†å“æå–ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨çŸ­è½®è¯¢ç­‰å¾…ã€å°½æ—©è¿”å›ï¼Œå‡å°‘å›ºå®š sleepï¼‰
        """
        products = []
        try:
            # å°è¾…åŠ©ï¼šåœ¨çŸ­æ—¶é—´å†…è½®è¯¢å¤šä¸ªé€‰æ‹©å™¨ï¼Œè¿”å›æ‰¾åˆ°çš„å…ƒç´ åˆ—è¡¨
            def wait_for_any_selector(selectors, total_timeout=4.0, poll_interval=0.4):
                elapsed = 0.0
                while elapsed < total_timeout:
                    for selector_type, selector in selectors:
                        if selector_type == 'xpath':
                            elems = self.page.eles(f'xpath:{selector}')
                        else:
                            elems = self.page.eles(selector)
                        if elems:
                            return elems
                    time.sleep(poll_interval)
                    elapsed += poll_interval
                return []

            selectors_to_try = [
                ('xpath', '//div[@role="listitem"][@data-asin]'),
                ('xpath', '//div[@data-component-type="s-search-result"]'),
                ('css', 'div.s-result-item[data-asin]'),
                ('xpath', '//div[contains(@class, "s-result-item")][@data-asin]'),
            ]

            # ä¼˜å…ˆçŸ­è½®è¯¢ç­‰å¾…ï¼ˆé»˜è®¤ total_timeout = 4sï¼‰
            product_elements = wait_for_any_selector(selectors_to_try, total_timeout=4.0, poll_interval=0.4)

            if not product_elements:
                # é€€å›åˆ°æ›´å®½æ¾çš„çŸ­ç­‰å¾…ï¼ˆæ€» 8sï¼‰
                product_elements = wait_for_any_selector(selectors_to_try, total_timeout=8.0, poll_interval=0.6)

            if not product_elements:
                print("âš ï¸ æœªæ‰¾åˆ°å•†å“å…ƒç´ ï¼ˆå·²çŸ­æ—¶é‡è¯•ï¼‰")
                return products

            print(f"âœ… æ‰¾åˆ° {len(product_elements)} ä¸ªå•†å“å…ƒç´ ï¼ˆé‡‡ç”¨çŸ­è½®è¯¢ï¼‰")

            for idx, element in enumerate(product_elements, 1):
                if detailed_mode:
                    product_data = self._extract_product_info_detailed(element, idx)
                else:
                    product_data = self._extract_product_info_basic(element, idx)

                if product_data:
                    products.append(product_data)
                    # ç²¾ç®€è¾“å‡ºï¼Œé¿å…å¤§é‡ I/O å½±å“æ€§èƒ½
                    asin = product_data.get('asin', 'N/A')
                    price_info = product_data.get('price_details') or {}
                    print(f"  âœ… å•†å“ {idx}: ASIN={asin} ä»·æ ¼={price_info.get('current_price', 'N/A')}")
                else:
                    print(f"  âš ï¸ å•†å“ {idx} æ•°æ®æå–å¤±è´¥")

            return products

        except Exception as e:
            print(f"âŒ æå–å•†å“åˆ—è¡¨å¤±è´¥: {e}")
            return products

    def _extract_title_description_enhanced(self, element) -> Tuple[Optional[str], Optional[str]]:
        """
        å¢å¼ºç‰ˆæ ‡é¢˜å’Œæè¿°æå–
        """
        title = None
        description = None

        try:
            # ç­–ç•¥1: æŸ¥æ‰¾å¸¦aria-labelçš„h2æ ‡ç­¾
            h2_elements = element.eles('xpath:.//h2[@aria-label]')
            for h2 in h2_elements:
                aria_label = h2.attr('aria-label')
                if aria_label and len(aria_label.strip()) > 10:
                    if not aria_label.isupper():
                        description = aria_label.strip()
                        title = aria_label.strip()
                        break

            # ç­–ç•¥2: å¦‚æœæ²¡æœ‰aria-labelï¼ŒæŸ¥æ‰¾h2å†…çš„spanæ–‡æœ¬
            if not title:
                h2_elements = element.eles('xpath:.//h2//span')
                for h2 in h2_elements:
                    text = h2.text
                    if text and len(text.strip()) > 15:
                        title = text.strip()
                        if not description:
                            description = text.strip()
                        break

            # ç­–ç•¥3: æŸ¥æ‰¾åŒ…å«å•†å“æè¿°çš„div
            if not description:
                desc_selectors = [
                    'xpath:.//div[contains(@class, "s-title-instructions-style")]',
                    'xpath:.//div[contains(@class, "a-section")]//span[contains(@class, "a-text-normal")]',
                    'xpath:.//span[contains(@class, "a-size-base-plus")]'
                ]
                for selector in desc_selectors:
                    desc_elements = element.eles(selector)
                    for desc in desc_elements:
                        text = desc.text
                        if text and len(text.strip()) > 20:
                            description = text.strip()
                            if not title:
                                title = text.strip()
                            break
                    if description:
                        break

            # æ¸…ç†å’Œæ ‡å‡†åŒ–
            if title:
                title = self._clean_text(title)
            if description:
                description = self._clean_text(description)
                if title and description == title:
                    description = None

            return title, description

        except Exception as e:
            print(f"âš ï¸ æå–æ ‡é¢˜æè¿°æ—¶å‡ºé”™: {e}")
            return title, description

    # python
    def _extract_product_info_basic(self, element, index) -> Optional[Dict]:
        """
        åŸºæœ¬å•†å“ä¿¡æ¯æå–ï¼šè¿”å›æœ€å°ä½†å¸¸ç”¨å­—æ®µï¼Œç”¨äºå¿«é€Ÿæ¨¡å¼ã€‚
        """
        try:
            prod = {'index': index}
            # ASIN
            asin = element.attr('data-asin') or None
            prod['asin'] = asin

            # é“¾æ¥
            link_ele = element.ele('xpath:.//h2//a') or element.ele(
                'xpath:.//a[@class="a-link-normal a-text-normal"]') or element.ele(
                'xpath:.//a[contains(@href,"/dp/") or contains(@href,"/gp/")]')
            detail_url = None
            if link_ele:
                href = link_ele.attr('href') or ''
                if href:
                    detail_url = urljoin(self.base_url, href)
            prod['detail_url'] = detail_url

            # æ ‡é¢˜ä¸æè¿°
            title, description = self._extract_title_description_enhanced(element)
            prod['title'] = title or ""
            prod['description'] = description or ""

            # å›¾ç‰‡
            prod['image'] = self._extract_image_url(element)

            # ä»·æ ¼ï¼ˆç»“æ„åŒ–ï¼‰
            price_details = self._extract_price_enhanced(element) or {}
            prod['price_details'] = price_details
            # å…¼å®¹é¡¶å±‚ current_price å­—æ®µï¼ˆè‹¥åç»­ä»£ç ä¾èµ–ï¼‰
            if price_details.get('current_price'):
                prod['current_price'] = price_details.get('current_price')

            # è¯„åˆ†ä¸è¯„è®ºæ•°
            try:
                rating_ele = element.ele('xpath:.//span[@class="a-icon-alt"]')
                rating_text = rating_ele.text if rating_ele else ""
                rating_match = re.search(r'([0-9]+(\.[0-9]+)?)', rating_text or "")
                prod['rating'] = float(rating_match.group(1)) if rating_match else None
            except:
                prod['rating'] = None

            try:
                review_ele = element.ele(
                    'xpath:.//span[@class="a-size-base" or contains(@class,"a-size-small")][normalize-space()]')
                if review_ele and review_ele.text:
                    rc = re.sub(r'[^\d]', '', review_ele.text)
                    prod['review_count'] = int(rc) if rc else None
                else:
                    prod['review_count'] = None
            except:
                prod['review_count'] = None

            # å“ç‰Œã€Primeã€Sponsored
            prod['brand'] = self._extract_brand_enhanced(element)
            prod['is_prime'] = bool(element.eles('xpath:.//i[contains(@aria-label,"Prime")]') or element.eles(
                'xpath:.//span[contains(@aria-label,"Prime")]'))
            prod['has_sponsored'] = bool(element.eles('xpath:.//span[contains(text(),"Sponsored")]') or element.eles(
                'xpath:.//span[contains(text(),"æ¨å¹¿")]') or ('sponsored' in (element.text or "").lower()))

            return prod

        except Exception as e:
            print(f"âš ï¸ æå–åŸºæœ¬å•†å“ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None

    def _extract_product_info_detailed(self, element, index) -> Optional[Dict]:
        """
        è¯¦ç»†å•†å“ä¿¡æ¯æå–ï¼šåœ¨åŸºæœ¬ä¿¡æ¯ä¸Šè¡¥å……ç‰¹æ€§ã€å˜ä½“ã€åº“å­˜ç­‰ï¼ˆè°ƒç”¨å·²æœ‰æ–¹æ³•ï¼‰ã€‚
        """
        try:
            prod = self._extract_product_info_basic(element, index) or {'index': index}
            # ç‰¹æ€§/å–ç‚¹
            try:
                prod['features'] = self._extract_product_features(element)
            except:
                prod['features'] = []

            # å˜ä½“
            try:
                prod['variants'] = self._extract_variants_info(element)
            except:
                prod['variants'] = []

            # è¿è¾“ä¿¡æ¯ä¸åº“å­˜
            try:
                prod['shipping'] = self._extract_shipping_info(element)
            except:
                prod['shipping'] = None

            try:
                prod['stock_status'] = self._extract_stock_status(element)
            except:
                prod['stock_status'] = None

            return prod

        except Exception as e:
            print(f"âš ï¸ æå–è¯¦ç»†å•†å“ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None

    def _extract_price_enhanced(self, element) -> Dict:
        """
        æ›´å®Œæ•´çš„ä»·æ ¼æå–å™¨ï¼š
        - ä¸€æ¬¡è¯»å– element.html / element.text
        - è¯†åˆ«å¸¸è§ Amazon ä»·æ ¼å±•ç¤ºï¼ˆa-offscreen, a-price, strike-through, price ranges, "from"/"starting at", Subscribe&Saveï¼‰
        - è¿”å›å…¼å®¹æ—§å­—æ®µå¹¶æ–°å¢æ•°å€¼åŒ–å­—æ®µï¼šcurrent_price_value, original_price_value, price_min, price_max, currency
        - å°½é‡ä¿æŒé€Ÿåº¦ï¼šä¼˜å…ˆ a-offscreenã€ä¸€æ¬¡æ€§æ­£åˆ™åŒ¹é…
        """
        price_data = {
            'current_price': None,
            'original_price': None,
            'discount': None,
            'discount_percentage': None,
            'savings': None,
            'shipping': None,
            'price_unit': 'USD',
            'price_type': None,
            # ä¸‹é¢æ˜¯æ–°å¢çš„æ•°å€¼åŒ–å­—æ®µï¼Œä¾¿äºæ’åº/è®¡ç®—
            'current_price_value': None,
            'original_price_value': None,
            'price_min': None,
            'price_max': None,
            'currency': None,
        }

        try:
            # é¢„ç¼–è¯‘æ­£åˆ™ï¼ˆæ•è·è´§å¸ç¬¦å·ä¸æ•°å­—éƒ¨åˆ†ï¼‰
            price_token_re = re.compile(r'([\$â‚¬Â£Â¥])\s*(\d{1,3}(?:[,\d]*)(?:\.\d{1,2})?)')
            range_re = re.compile(r'([\$â‚¬Â£Â¥]\s*\d[\d,\.\s]*?)\s*[-~â€“]\s*([\$â‚¬Â£Â¥]\s*\d[\d,\.\s]*?)')
            from_re = re.compile(r'(^|\b)(from|starting at|starts at)\b', re.I)
            pct_re = re.compile(r'(\d{1,3})\s*%')
            save_re = re.compile(r'(?:Save|Save up to)\s*[:\-]?\s*[\$â‚¬Â£Â¥]?\s*(\d{1,3}(?:[,\d]*)(?:\.\d{1,2})?)', re.I)
            shipping_re = re.compile(r'(FREE\s+Shipping|Free Shipping|Shipping[:\s]|Delivery[:\s])', re.I)

            # è¯»å–æ–‡æœ¬/HTML
            full_text = (element.text or "").strip()
            try:
                full_html = element.html or ""
            except Exception:
                full_html = ""
            combined = full_html + "\n" + full_text

            # helper: è§„èŒƒåŒ–ä»·æ ¼å­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸º float
            def parse_price_token(token: str):
                if not token:
                    return None, None
                m = price_token_re.search(token)
                if not m:
                    return None, None
                symbol = m.group(1)
                num = m.group(2).replace(',', '').replace(' ', '')
                try:
                    val = float(num)
                except Exception:
                    val = None
                return symbol, val

            # 1) ä¼˜å…ˆå– a-offscreenï¼ˆAmazon é€šå¸¸æŠŠè¯­ä¹‰åŒ–ä»·æ ¼æ”¾åœ¨è¿™é‡Œï¼‰
            try:
                off_nodes = element.eles('xpath:.//span[@class="a-offscreen"]')
            except Exception:
                off_nodes = []

            if off_nodes:
                off_texts = [(n.text or '').strip() for n in off_nodes if (n.text or '').strip()]
                if off_texts:
                    # ç¬¬ä¸€æ¡é€šå¸¸æ˜¯ç°ä»·
                    cur_raw = off_texts[0].replace('\u00a0', ' ')
                    price_data['current_price'] = cur_raw
                    sym, val = parse_price_token(cur_raw)
                    if sym and val is not None:
                        price_data['currency'] = sym
                        price_data['current_price_value'] = val
                        price_data['price_unit'] = 'USD' if sym == '$' else ('EUR' if sym == 'â‚¬' else ('GBP' if sym == 'Â£' else 'JPY'))
                    # å¦‚æœæœ‰ç¬¬äºŒæ¡ï¼Œå¯èƒ½ä¸ºåŸä»·
                    if len(off_texts) >= 2:
                        orig_raw = off_texts[1].replace('\u00a0', ' ')
                        price_data['original_price'] = orig_raw
                        sym2, val2 = parse_price_token(orig_raw)
                        if sym2 and val2 is not None:
                            price_data['original_price_value'] = val2

            # 2) è‹¥æ²¡æœ‰ a-offscreen çš„ç»“æœï¼Œä½¿ç”¨èŒƒå›´æˆ–å…¨æ–‡åŒ¹é…ï¼ˆä¸€æ¬¡æ€§ï¼‰
            if not price_data['current_price']:
                # ä»·æ ¼èŒƒå›´
                rm = range_re.search(combined)
                if rm:
                    low_raw = rm.group(1).replace('\u00a0', ' ')
                    high_raw = rm.group(2).replace('\u00a0', ' ')
                    price_data['current_price'] = f"{low_raw} - {high_raw}"
                    price_data['price_type'] = 'range'
                    s1, v1 = parse_price_token(low_raw)
                    s2, v2 = parse_price_token(high_raw)
                    if v1 is not None:
                        price_data['price_min'] = v1
                    if v2 is not None:
                        price_data['price_max'] = v2
                    # set currency if available
                    if s1:
                        price_data['currency'] = s1
                else:
                    # æŠ½å–é¡µé¢ä¸­æ‰€æœ‰ä»·æ ¼ tokenï¼Œç¬¬ä¸€é¡¹ä¸ºç°ä»·ï¼Œç¬¬äºŒé¡¹ä¸ºåŸä»·ï¼ˆå¸¸è§ï¼‰
                    all_tokens = price_token_re.findall(combined)
                    if all_tokens:
                        # price_token_re.findall returns list of tuples (sym, num)
                        # reconstruct strings
                        tokens = [f"{t[0]}{t[1]}" for t in all_tokens]
                        cur_raw = tokens[0].replace('\u00a0', ' ')
                        price_data['current_price'] = cur_raw
                        s, v = parse_price_token(cur_raw)
                        if s and v is not None:
                            price_data['currency'] = s
                            price_data['current_price_value'] = v
                            price_data['price_unit'] = 'USD' if s == '$' else ('EUR' if s == 'â‚¬' else ('GBP' if s == 'Â£' else 'JPY'))
                        if len(tokens) >= 2:
                            orig_raw = tokens[1].replace('\u00a0', ' ')
                            price_data['original_price'] = orig_raw
                            s2, v2 = parse_price_token(orig_raw)
                            if v2 is not None:
                                price_data['original_price_value'] = v2

            # 3) è¯†åˆ« "from" / "starting at" æ–‡æœ¬ï¼ˆå¦‚æœä»·æ ¼æ˜¯èµ·ä»·ï¼‰
            if price_data['current_price'] and from_re.search(combined):
                price_data['price_type'] = 'from'

            # 4) è®¡ç®—æŠ˜æ‰£ä¸èŠ‚çœï¼ˆè‹¥æä¾›åŸä»·å’Œç°ä»·ï¼‰
            if price_data.get('current_price_value') is None and price_data.get('current_price'):
                # attempt to get numeric if current_price is a single token
                sym, v = parse_price_token(price_data['current_price'])
                if v is not None:
                    price_data['current_price_value'] = v
                    if sym:
                        price_data['currency'] = sym

            if price_data.get('original_price_value') is None and price_data.get('original_price'):
                sym, v = parse_price_token(price_data['original_price'])
                if v is not None:
                    price_data['original_price_value'] = v

            if price_data.get('current_price_value') is not None and price_data.get('original_price_value') is not None:
                try:
                    cur = price_data['current_price_value']
                    orig = price_data['original_price_value']
                    if orig > 0 and orig >= cur:
                        diff = orig - cur
                        pct = (diff / orig) * 100
                        price_data['discount'] = f"${diff:.2f}"
                        price_data['discount_percentage'] = f"{pct:.1f}%"
                        price_data['savings'] = f"Save ${diff:.2f} ({pct:.1f}%)"
                except Exception:
                    pass

            # 5) è‹¥æŠ˜æ‰£å­—æ®µç¼ºå¤±ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­è¡¥å……
            if not price_data.get('discount_percentage'):
                pm = pct_re.search(combined)
                if pm:
                    price_data['discount_percentage'] = f"{pm.group(1)}%"
            if not price_data.get('savings'):
                sm = save_re.search(combined)
                if sm:
                    val = sm.group(1).replace(',', '')
                    price_data['savings'] = f"Save ${val}"

            # 6) æŠ½å–è¿è¾“ä¿¡æ¯
            shipm = shipping_re.search(combined)
            if shipm:
                price_data['shipping'] = shipm.group(1).strip()

            # 7) è¡¥é½ price_min/price_max è‹¥å°šæœªè®¾ç½®
            if price_data.get('current_price_value') is not None and price_data.get('price_min') is None:
                price_data['price_min'] = price_data['current_price_value']
            if price_data.get('current_price_value') is not None and price_data.get('price_max') is None:
                price_data['price_max'] = price_data['current_price_value']

            # 8) è§„èŒƒ currency å­—æ®µä¸ºç¬¦å·/ä»£ç 
            if price_data.get('currency'):
                sym = price_data['currency']
                code = 'USD' if sym == '$' else ('EUR' if sym == 'â‚¬' else ('GBP' if sym == 'Â£' else 'JPY'))
                price_data['price_unit'] = code
                price_data['currency'] = sym

            return price_data

        except Exception as e:
            print(f"âš ï¸ æå–ä»·æ ¼ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return price_data

    def _extract_brand_enhanced(self, element) -> Optional[str]:
        """
        å¢å¼ºç‰ˆå“ç‰Œæå–
        """
        try:
            brand_selectors = [
                'xpath:.//span[@class="a-size-base-plus a-color-base"]',
                'xpath:.//h2[contains(@class, "a-size-mini")]//span',
                'xpath:.//span[contains(@class, "a-text-bold")]',
                'xpath:.//a[contains(@href, "/s?k=")]//span',
            ]

            for selector in brand_selectors:
                brand_elements = element.eles(selector)
                if brand_elements:
                    for brand_ele in brand_elements:
                        brand_text = brand_ele.text or ""
                        if brand_text and len(brand_text.strip()) > 1:
                            lower_text = brand_text.lower()
                            if len(brand_text) > 15 or lower_text in ['sponsored', 'advertisement']:
                                continue
                            return brand_text.strip()

            # å¦‚æœä¸Šè¿°æ–¹æ³•æ²¡æ‰¾åˆ°ï¼Œå°è¯•ä»æ ‡é¢˜ä¸­æå–å¯èƒ½å“ç‰Œ
            title_elements = element.eles('xpath:.//h2')
            if title_elements:
                for title_ele in title_elements:
                    title_text = title_ele.text or ""
                    words = title_text.split()
                    if len(words) >= 2:
                        if words[0].istitle() and len(words[0]) <= 20:
                            return words[0]

            return None

        except Exception as e:
            print(f"âš ï¸ æå–å“ç‰Œä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None
    def _extract_image_url(self, element) -> Optional[str]:
        """
        æå–å›¾ç‰‡URL
        """
        try:
            img_selectors = [
                'xpath:.//img[@class="s-image"]',
                'xpath:.//img[contains(@data-image-latency, "s-product-image")]',
            ]

            for selector in img_selectors:
                img_elements = element.eles(selector)
                if img_elements:
                    for img_ele in img_elements:
                        src = img_ele.attr('src') or img_ele.attr('data-src')
                        if src and src.startswith('http'):
                            return src
            return None

        except Exception as e:
            print(f"âš ï¸ æå–å›¾ç‰‡URLæ—¶å‡ºé”™: {e}")
            return None

    def _extract_product_features(self, element) -> List[str]:
        """
        æå–å•†å“ç‰¹æ€§/å–ç‚¹
        """
        try:
            features = []
            feature_selectors = [
                'xpath:.//div[contains(@class, "a-color-secondary")]//span',
                'xpath:.//ul[@class="a-unordered-list"]//span',
            ]

            for selector in feature_selectors:
                feature_elements = element.eles(selector)
                for feature_ele in feature_elements:
                    feature_text = feature_ele.text or ""
                    if feature_text and len(feature_text.strip()) > 5:
                        cleaned = self._clean_text(feature_text)
                        features.append(cleaned)

            return features[:5]

        except Exception as e:
            print(f"âš ï¸ æå–å•†å“ç‰¹æ€§æ—¶å‡ºé”™: {e}")
            return []

    def _extract_shipping_info(self, element) -> Optional[str]:
        """
        æå–è¿è¾“ä¿¡æ¯
        """
        try:
            shipping_selectors = [
                'xpath:.//span[contains(text(), "FREE Shipping")]',
                'xpath:.//span[contains(text(), "Delivery")]',
                'xpath:.//span[contains(@aria-label, "FREE Shipping")]',
            ]

            for selector in shipping_selectors:
                shipping_elements = element.eles(selector)
                if shipping_elements:
                    shipping_text = shipping_elements[0].text or ""
                    if shipping_text:
                        return shipping_text.strip()
            return None

        except Exception as e:
            print(f"âš ï¸ æå–è¿è¾“ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None

    def _extract_stock_status(self, element) -> Optional[str]:
        """
        æå–åº“å­˜çŠ¶æ€
        """
        try:
            stock_selectors = [
                'xpath:.//span[contains(text(), "In Stock")]',
                'xpath:.//span[contains(text(), "Only") and contains(text(), "left")]',
                'xpath:.//span[contains(text(), "Out of Stock")]',
            ]

            for selector in stock_selectors:
                stock_elements = element.eles(selector)
                if stock_elements:
                    stock_text = stock_elements[0].text or ""
                    if stock_text:
                        return stock_text.strip()
            return None

        except Exception as e:
            print(f"âš ï¸ æå–åº“å­˜çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return None

    def _extract_variants_info(self, element) -> List[Dict]:
        """
        æå–å˜ä½“ä¿¡æ¯
        """
        try:
            variants = []
            variant_selectors = [
                'xpath:.//div[contains(@class, "a-row a-size-base")]//span',
                'xpath:.//ul[contains(@class, "a-unordered-list")]//li',
            ]

            for selector in variant_selectors:
                variant_elements = element.eles(selector)
                for variant_ele in variant_elements:
                    variant_text = variant_ele.text or ""
                    if variant_text and ('Color:' in variant_text or 'Size:' in variant_text):
                        variants.append({'text': variant_text.strip()})

            return variants[:3]

        except Exception as e:
            print(f"âš ï¸ æå–å˜ä½“ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return []


    def _clean_text(self, text: str) -> str:
        """
        æ¸…ç†æ–‡æœ¬
        """
        if not text:
            return ""

        text = re.sub(r'\s+', ' ', text)
        text = text.strip()
        text = re.sub(r'[\x00-\x08\x0B\x0C\x0E-\x1F\x7F]', '', text)

        return text

    def _go_next_page(self) -> bool:
        """
        ç¿»åˆ°ä¸‹ä¸€é¡µ
        """
        try:
            next_page_selector = 'a.s-pagination-next'

            next_btn = self.page.ele(next_page_selector, timeout=5)

            if next_btn and 's-pagination-disabled' not in (next_btn.attr('class') or ''):
                next_btn.click()
                print("âœ… å·²ç¿»é¡µ")
                return True
            else:
                print("âš ï¸ ä¸‹ä¸€é¡µæŒ‰é’®ä¸å¯ç”¨")
                return False

        except Exception as e:
            print(f"âŒ ç¿»é¡µå¤±è´¥: {e}")
            return False

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.page:
            self.page.quit()
            print("æµè§ˆå™¨å·²å…³é—­")

    def save_results(self, products: List[Dict], filename: str = None):
        """
        ä¿å­˜çˆ¬å–ç»“æœåˆ°JSONå’ŒCSVæ–‡ä»¶ï¼ŒåŒ…å«ç”¨äºåç»­APIçš„æ•°æ®è¡¨æ ¼å­—æ®µï¼š
        - index, asin, title, description, detail_url
        - price (åŸå§‹å­—ç¬¦ä¸²), price_value (current numeric), currency, price_min, price_max
        - original_price, original_price_value, discount_percentage, savings, shipping
        è¿™æ ·CSVå¯ç›´æ¥ä½œä¸ºè½»é‡æ•°æ®è¡¨å¯¹å¤–æä¾›æˆ–å¯¼å…¥æ•°æ®åº“ã€‚
        """
        if not filename:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            filename = f"amazon_search_results_{timestamp}.json"

        # æ„å»ºå®Œæ•´äº§å“è¡¨ï¼ˆåŒ…å«æ•°å€¼å­—æ®µï¼Œä¾¿äºåç»­ API ä½¿ç”¨ï¼‰
        table_products = []
        for idx, p in enumerate(products, 1):
            price_details = p.get('price_details') or {}
            # å°è¯•ä¼˜å…ˆè·å–æ ‡å‡†åŒ–å­—æ®µ
            price_str = price_details.get('current_price') or p.get('current_price') or ""
            price_value = price_details.get('current_price_value')
            currency_sym = price_details.get('currency') or price_details.get('price_unit') or None
            price_min = price_details.get('price_min')
            price_max = price_details.get('price_max')
            original_price = price_details.get('original_price')
            original_price_value = price_details.get('original_price_value')
            discount_pct = price_details.get('discount_percentage')
            savings = price_details.get('savings')
            shipping = price_details.get('shipping') or p.get('shipping')

            table_products.append({
                'index': idx,
                'asin': p.get('asin') or "",
                'title': p.get('title') or "",
                'description': p.get('description') or "",
                'detail_url': p.get('detail_url') or "",
                'price': price_str or "",
                'price_value': price_value if price_value is not None else "",
                'currency': currency_sym or "",
                'price_min': price_min if price_min is not None else "",
                'price_max': price_max if price_max is not None else "",
                'original_price': original_price or "",
                'original_price_value': original_price_value if original_price_value is not None else "",
                'discount_percentage': discount_pct or "",
                'savings': savings or "",
                'shipping': shipping or "",
            })

        data_to_save = {
            'crawled_at': time.strftime('%Y-%m-%d %H:%M:%S'),
            'total_products': len(table_products),
            'products': table_products
        }

        # ä¿å­˜ JSONï¼ˆå®Œæ•´è¡¨ï¼‰
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(data_to_save, f, ensure_ascii=False, indent=2)
            print(f"âœ… å®Œæ•´ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        except Exception as e:
            print(f"âš ï¸ ä¿å­˜JSONæ—¶å‡ºé”™: {e}")

        # ä¿å­˜ CSVï¼ˆåŒ…å«æ‰€æœ‰å¯¹å¤–éœ€è¦çš„åˆ—ï¼Œä¾¿äºç›´æ¥å½“ä½œæ•°æ®è¡¨æä¾›ç»™ API æˆ–å¯¼å…¥ DBï¼‰
        csv_filename = filename.replace('.json', '.csv')
        self._save_to_csv(table_products, csv_filename)

    def _save_to_csv(self, products: List[Dict], filename: str):
        """
        å°†å®Œæ•´çš„äº§å“è¡¨ä¿å­˜ä¸º CSVï¼Œåˆ—åŒ…æ‹¬ï¼š
        index, asin, title, description, detail_url, price, price_value, currency,
        price_min, price_max, original_price, original_price_value, discount_percentage, savings, shipping
        """
        try:
            fieldnames = [
                'index', 'asin', 'title', 'description', 'detail_url',
                'price', 'price_value', 'currency', 'price_min', 'price_max',
                'original_price', 'original_price_value', 'discount_percentage', 'savings', 'shipping'
            ]
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                for product in products:
                    # ä»…å†™å…¥æ‰€éœ€åˆ—ï¼Œä¿è¯å­—æ®µé¡ºåºä¸è¡¨å¤´ä¸€è‡´
                    row = {k: product.get(k, '') for k in fieldnames}
                    writer.writerow(row)

            print(f"âœ… CSVæ•°æ®è¡¨å·²ä¿å­˜: {filename}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•° - è¿è¡Œçˆ¬è™«çš„ç¤ºä¾‹"""
    import sys

    print("ğŸ” Amazon æœç´¢çˆ¬è™« - å¢å¼ºç‰ˆ")
    print("=" * 50)

    # # 1.1é…ç½®é€‰é¡¹
    # config = {
    #     'headless': True,  # æ”¹ä¸º Trueï¼ˆæ— å¤´æ¨¡å¼ï¼‰
    #     'use_saved_login': False,  # æ”¹ä¸º Falseï¼ˆä¸ä½¿ç”¨ä¿å­˜çš„ç™»å½•ï¼‰
    #     'browser_type': 'edge',  #
    #     'max_pages': 1,  # åªçˆ¬1é¡µ
    #     'detailed_extraction': False,  # å¿«é€Ÿæ¨¡å¼
    # }

    # 1.2é…ç½®é€‰é¡¹
    config = {
        'headless': False,  # æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œ
        'use_saved_login': True,  # æ˜¯å¦ä½¿ç”¨ä¿å­˜çš„ç™»å½•ä¿¡æ¯
        'browser_type': 'edge',  # æµè§ˆå™¨ç±»å‹ï¼šedge æˆ– chrome
        'max_pages': 2,  # æœ€å¤§çˆ¬å–é¡µæ•°
        'detailed_extraction': True,  # æ˜¯å¦å¯ç”¨è¯¦ç»†æå–
    }
    # åˆ›å»ºçˆ¬è™«å®ä¾‹
    print("æ­£åœ¨åˆå§‹åŒ–æµè§ˆå™¨...")
    crawler = EnhancedAmazonSearchCrawler(
        headless=config['headless'],
        use_saved_login=config['use_saved_login'],
        browser_type=config['browser_type']
    )

    try:
        # æœç´¢å…³é”®è¯
        keywords = [
            "wireless headphones",
            "laptop bag",
            "coffee maker",
            "yoga mat",
            "smart watch"
        ]

        print("\nè¯·é€‰æ‹©æœç´¢å…³é”®è¯:")
        for i, keyword in enumerate(keywords, 1):
            print(f"  {i}. {keyword}")
        print(f"  6. è‡ªå®šä¹‰å…³é”®è¯")

        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-6): ").strip()

        if choice == '6':
            keyword = input("è¯·è¾“å…¥è‡ªå®šä¹‰æœç´¢å…³é”®è¯: ").strip()
        elif choice.isdigit() and 1 <= int(choice) <= 5:
            keyword = keywords[int(choice) - 1]
        else:
            print("âš ï¸ æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯")
            keyword = keywords[0]

        print(f"\nğŸ” å¼€å§‹æœç´¢: {keyword}")
        print("=" * 60)

        # å¼€å§‹çˆ¬å–
        start_time = time.time()

        products = crawler.search_products(
            keyword=keyword,
            max_pages=config['max_pages'],
            detailed_extraction=config['detailed_extraction']
        )

        end_time = time.time()
        elapsed_time = end_time - start_time

        # æ‰“å°è¯¦ç»†ç»Ÿè®¡
        print("\n" + "=" * 60)
        print("ğŸ“Š çˆ¬å–ç»“æœç»Ÿè®¡")
        print("=" * 60)

        # ç»Ÿè®¡ä¿¡æ¯
        total_products = len(products)
        products_with_price = sum(1 for p in products if p.get('price_details', {}).get('current_price'))
        products_with_rating = sum(1 for p in products if p.get('rating'))
        prime_products = sum(1 for p in products if p.get('is_prime'))
        sponsored_products = sum(1 for p in products if p.get('has_sponsored'))

        print(f"æ€»å•†å“æ•°: {total_products}")
        print(f"æœ‰ä»·æ ¼çš„å•†å“: {products_with_price}")
        print(f"æœ‰è¯„åˆ†çš„å•†å“: {products_with_rating}")
        print(f"Primeå•†å“: {prime_products}")
        print(f"æ¨å¹¿å•†å“: {sponsored_products}")
        print(f"çˆ¬å–æ—¶é—´: {elapsed_time:.2f} ç§’")

        # ä»·æ ¼åˆ†å¸ƒåˆ†æ
        prices = []
        for p in products:
            price_data = p.get('price_details', {})
            if price_data.get('current_price'):
                try:
                    price_str = price_data['current_price']
                    # æå–æ•°å­—éƒ¨åˆ†ï¼ˆå¤„ç†ä»·æ ¼èŒƒå›´ï¼‰
                    if '-' in price_str:
                        # å–æœ€ä½ä»·
                        price_match = re.search(r'[\$â‚¬Â£Â¥]\s*(\d+\.?\d*)', price_str)
                        if price_match:
                            prices.append(float(price_match.group(1)))
                    else:
                        price_num = re.search(r'(\d+\.?\d*)', price_str)
                        if price_num:
                            prices.append(float(price_num.group(1)))
                except Exception as e:
                    continue

        if prices:
            avg_price = sum(prices) / len(prices)
            max_price = max(prices)
            min_price = min(prices)
            print(f"\nğŸ’° ä»·æ ¼åˆ†æ:")
            print(f"  å¹³å‡ä»·æ ¼: ${avg_price:.2f}")
            print(f"  æœ€é«˜ä»·æ ¼: ${max_price:.2f}")
            print(f"  æœ€ä½ä»·æ ¼: ${min_price:.2f}")
            print(f"  ä»·æ ¼èŒƒå›´: ${min_price:.2f} - ${max_price:.2f}")

        # æ˜¾ç¤ºå‰5ä¸ªå•†å“çš„è¯¦ç»†ä¿¡æ¯
        if products:
            print(f"\nğŸ“‹ å‰5ä¸ªå•†å“è¯¦æƒ…:")
            print("-" * 60)

            for idx, product in enumerate(products[:5], 1):
                print(f"\nå•†å“ #{product.get('index', idx)}:")
                print(f"  ASIN: {product.get('asin', 'N/A')}")

                # æ ‡é¢˜å’Œæè¿°
                if product.get('title'):
                    title = product['title']
                    if len(title) > 60:
                        title = title[:57] + "..."
                    print(f"  æ ‡é¢˜: {title}")

                if product.get('description') and product['description'] != product.get('title'):
                    desc = product['description']
                    if len(desc) > 80:
                        desc = desc[:77] + "..."
                    print(f"  æè¿°: {desc}")

                # ä»·æ ¼ä¿¡æ¯4

                price_data = product.get('price_details', {})
                if price_data:
                    print(f"  ä»·æ ¼ä¿¡æ¯:")
                    if price_data.get('current_price'):
                        print(f"    ç°ä»·: {price_data['current_price']}")
                    if price_data.get('original_price'):
                        print(f"    åŸä»·: {price_data['original_price']}")
                    if price_data.get('discount_percentage'):
                        print(f"    æŠ˜æ‰£: {price_data['discount_percentage']}")
                    if price_data.get('shipping'):
                        print(f"    è¿è´¹: {price_data['shipping']}")

                # è¯„åˆ†ä¿¡æ¯
                if product.get('rating'):
                    rating_str = f"è¯„åˆ†: {product['rating']}/5"
                    if product.get('review_count'):
                        rating_str += f" ({product['review_count']}æ¡è¯„è®º)"
                    print(f"  {rating_str}")

                # å“ç‰Œ
                if product.get('brand'):
                    print(f"  å“ç‰Œ: {product['brand']}")

                # PrimeçŠ¶æ€
                if product.get('is_prime'):
                    print(f"  âœ… Primeå•†å“")

                if product.get('has_sponsored'):
                    print(f"  âš ï¸ æ¨å¹¿å•†å“")

                if product.get('detail_url'):
                    print(f"  é“¾æ¥: {product['detail_url'][:80]}...")

        # ä¿å­˜ç»“æœ
        if products:
            crawler.save_results(products)

            # æ˜¾ç¤ºä»·æ ¼æœ€ä¾¿å®œçš„å‰5ä¸ªå•†å“
            products_with_price = [p for p in products if p.get('price_details', {}).get('current_price')]
            if products_with_price:
                # æŒ‰ä»·æ ¼æ’åº
                def get_price(product):
                    try:
                        price_str = product['price_details']['current_price']
                        # å¤„ç†ä»·æ ¼èŒƒå›´
                        if '-' in price_str:
                            price_match = re.search(r'[\$â‚¬Â£Â¥]\s*(\d+\.?\d*)', price_str)
                            return float(price_match.group(1)) if price_match else float('inf')
                        else:
                            price_num = re.search(r'(\d+\.?\d*)', price_str)
                            return float(price_num.group(1)) if price_num else float('inf')
                    except:
                        return float('inf')

                sorted_products = sorted(products_with_price, key=get_price)

                print(f"\nğŸ’¸ æœ€ä¾¿å®œçš„5ä¸ªå•†å“:")
                print("-" * 60)
                for idx, product in enumerate(sorted_products[:5], 1):
                    price = product['price_details']['current_price']
                    title = product.get('title', 'N/A')
                    if len(title) > 50:
                        title = title[:47] + "..."
                    print(f"{idx}. {price} - {title}")

        print(f"\nâœ… çˆ¬å–å®Œæˆï¼å…±è·å– {len(products)} ä¸ªå•†å“æ•°æ®")

    except KeyboardInterrupt:
        print("\n\nâ¹ï¸ ç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
    finally:
        # å…³é—­æµè§ˆå™¨
        crawler.close()
        print("\nğŸ¯ ç¨‹åºæ‰§è¡Œå®Œæ¯•")


# è¿è¡Œä¸»å‡½æ•°
if __name__ == '__main__':
    main()